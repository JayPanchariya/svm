{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXIQSGPX85ir"
      },
      "source": [
        "#From Linear classifiers to SVMs\n",
        "** Ecole Centrale Nantes **\n",
        "\n",
        "** Diana Mateus **\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPbG0deQ85ix"
      },
      "source": [
        "PARTICIPANTS: **(Fill in your names)**\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m This environment is externally managed\n",
            "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try brew install\n",
            "\u001b[31m   \u001b[0m xyz, where xyz is the package you are trying to\n",
            "\u001b[31m   \u001b[0m install.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you wish to install a Python library that isn't in Homebrew,\n",
            "\u001b[31m   \u001b[0m use a virtual environment:\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m python3 -m venv path/to/venv\n",
            "\u001b[31m   \u001b[0m source path/to/venv/bin/activate\n",
            "\u001b[31m   \u001b[0m python3 -m pip install xyz\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you wish to install a Python application that isn't in Homebrew,\n",
            "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
            "\u001b[31m   \u001b[0m virtual environment for you. You can install pipx with\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m brew install pipx\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m You may restore the old behavior of pip by passing\n",
            "\u001b[31m   \u001b[0m the '--break-system-packages' flag to pip, or by adding\n",
            "\u001b[31m   \u001b[0m 'break-system-packages = true' to your pip.conf file. The latter\n",
            "\u001b[31m   \u001b[0m will permanently disable this error.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you disable this error, we STRONGLY recommend that you additionally\n",
            "\u001b[31m   \u001b[0m pass the '--user' flag to pip, or set 'user = true' in your pip.conf\n",
            "\u001b[31m   \u001b[0m file. Failure to do this can result in a broken Homebrew installation.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m Read more about this behavior here: <https://peps.python.org/pep-0668/>\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
            "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
          ]
        }
      ],
      "source": [
        "!python3.13 -m pip install --upgrade pip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.13 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m This environment is externally managed\n",
            "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try brew install\n",
            "\u001b[31m   \u001b[0m xyz, where xyz is the package you are trying to\n",
            "\u001b[31m   \u001b[0m install.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you wish to install a Python library that isn't in Homebrew,\n",
            "\u001b[31m   \u001b[0m use a virtual environment:\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m python3 -m venv path/to/venv\n",
            "\u001b[31m   \u001b[0m source path/to/venv/bin/activate\n",
            "\u001b[31m   \u001b[0m python3 -m pip install xyz\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you wish to install a Python application that isn't in Homebrew,\n",
            "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
            "\u001b[31m   \u001b[0m virtual environment for you. You can install pipx with\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m brew install pipx\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m You may restore the old behavior of pip by passing\n",
            "\u001b[31m   \u001b[0m the '--break-system-packages' flag to pip, or by adding\n",
            "\u001b[31m   \u001b[0m 'break-system-packages = true' to your pip.conf file. The latter\n",
            "\u001b[31m   \u001b[0m will permanently disable this error.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m If you disable this error, we STRONGLY recommend that you additionally\n",
            "\u001b[31m   \u001b[0m pass the '--user' flag to pip, or set 'user = true' in your pip.conf\n",
            "\u001b[31m   \u001b[0m file. Failure to do this can result in a broken Homebrew installation.\n",
            "\u001b[31m   \u001b[0m \n",
            "\u001b[31m   \u001b[0m Read more about this behavior here: <https://peps.python.org/pep-0668/>\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
            "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install skimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ocTv1dr885iy"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'skimage'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Modules for image processing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rgb2gray\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Modules for image processing\n",
        "import skimage\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "\n",
        "#Modules for machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "#Useful for manual data splitting\n",
        "import random\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z79Frcx85i4"
      },
      "source": [
        "\n",
        "# 1. Loading and splitting data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYBvODRD85i5"
      },
      "source": [
        "**a)** Download the animals10classes dataset from hippocampus, which is a subset of the Caltech 101 dataset (http://www.vision.caltech.edu/Image_Datasets/Caltech101/Caltech101.html). The animals subset is composed of images belonging to one among 10 classes. Run the code bellow to check images and labels are read correctly and store the name of the classes in the list ```labelNamesAll```. If present after unziping the dataset, remove the _MACOSX directory as it is not needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMFXMn5oBcQI"
      },
      "outputs": [],
      "source": [
        "# Uncomment if using COLAB  (and comment next cell)\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#IMDIR = ('/content/drive/MyDrive/DATA/animals10classes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NKCjlWRBLc7"
      },
      "outputs": [],
      "source": [
        "# Uncomment if running locally (comment if running in COLAB)\n",
        "# Change with your own path\n",
        "IMDIR = '/Users/dianamateus/DATA/101Caltech/animals10classes/'\n",
        "# For Windows OS use IMIDR=r'/Users/dianamateus/DATA/101Caltech/animals10classes/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8Z0Hj8E85i6"
      },
      "outputs": [],
      "source": [
        "#Keep4students\n",
        "def loadImagesAndLabels(IMDIR):\n",
        "  #This function glances through all subdirectories in IMDIR,\n",
        "  #and creates a list of the subdirectory names, which will be\n",
        "  #used as labels for all the images within.The function returns\n",
        "  #the list of labels\n",
        "  #\n",
        "  #If the function returns an empty list, it is likely that IMDIR\n",
        "  #is not defined correctly. In that case uncomment the lines below\n",
        "  #to check the files that are actually being read.\n",
        "\n",
        "  labelNamesAll = []\n",
        "\n",
        "  for root, dirnames, filenames in os.walk(IMDIR):\n",
        "      labelNamesAll.append(dirnames)\n",
        "      #uncomment to check if the folder contains images\n",
        "      #for filename in filenames:\n",
        "      #   f = os.path.join(root, filename)\n",
        "      #   if f.endswith(('.png', '.jpg', '.jpeg','.JPG', '.tif', '.gif')):\n",
        "      #       print(f)\n",
        "\n",
        "  labelNamesAll = labelNamesAll[0]\n",
        "  return labelNamesAll\n",
        "\n",
        "#Call the function and\n",
        "#print the list of all labels/subdirectories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQKa2DBl85i8"
      },
      "source": [
        "**b).** Use the BuildDataset function to create a reduced dataset. In this notebook we will notably deal with binary classification problems. Print the sizes of the data matrix X and the label vector Y. Print as well the retained list of labels and the content of Y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZCnlt7x85i-"
      },
      "outputs": [],
      "source": [
        "#Keep4students\n",
        "def buildDataset (IMDIR,labelNamesAll,K=2,N=100,imHeight=100,imWidth=100,seed=50):\n",
        "    #This function builds the data matrix from (a subset) of the label list.\n",
        "    #Images are read using a composition of the path and the label list.\n",
        "    #Parameters of this functions are:\n",
        "    # K : the number of classes to consider\n",
        "    # N : the maximum number of images to read from each category (the number\n",
        "    #    of images per label is variable).\n",
        "    # imHeight,imWidth: define the size of the target image. All read images\n",
        "    #                  are resized to imHeight x imWidth\n",
        "    # seed : fixes the random seed to be able to reproduce the results.\n",
        "    # The function returns the data matrix X and the label vector Y.\n",
        "    # Ideally, the X matrix will be of size (KxN)x(ImHeight x ImWidth) but\n",
        "    # the number of rows will be less if the number of images in a given\n",
        "    # category is smaller than N\n",
        "\n",
        "    X = np.zeros([K*N,imHeight*imWidth]) #data matrix, one image per row\n",
        "    Y = -np.ones([K*N,1]) #label indices initiallized to -1\n",
        "    labelNames = [] #list of retained categories\n",
        "\n",
        "    random.seed(a=seed) #comment to make each run random\n",
        "\n",
        "    globalCount = 0 #counts the actual number of images copied to the datamatrix\n",
        "\n",
        "    # Iterate over the number of classes\n",
        "    for i in range(K):\n",
        "        #Randomly choose a new category\n",
        "        while True:\n",
        "            lab = random.randint(0,len(labelNamesAll)-1)\n",
        "            if lab not in labelNames:\n",
        "                break\n",
        "\n",
        "        #define the path to read the images of the chosen label.\n",
        "        #folders are named after the class label, print the chosen label\n",
        "        filedir = os.path.join(IMDIR,labelNamesAll[lab])\n",
        "        print('The chosen label ',i, ' is ',labelNamesAll[lab])\n",
        "        print('It will be read in',filedir)\n",
        "\n",
        "        #save the name of the class in labelNames\n",
        "        labelNames.append(labelNamesAll[lab])\n",
        "\n",
        "        #walk through the files of the label folder,\n",
        "        #read images in grayscale and resize them\n",
        "        #flatten the images to a vector\n",
        "        #copy each image to one row of the data matrix\n",
        "        #use classCount to retain at most N images per class\n",
        "        #use globalCount to keep track of the total number of images\n",
        "        classCount = 0\n",
        "        for filename in os.listdir(filedir):\n",
        "            f = os.path.join(filedir, filename)\n",
        "            if f.endswith(('.jpg')) and (classCount < N):\n",
        "                image = skimage.io.imread(f, as_gray=True)\n",
        "                image = skimage.transform.resize(image, [imHeight,imWidth],mode='constant')#,anti_aliasing=True)\n",
        "                X[globalCount,:] = image.flatten()\n",
        "                Y[globalCount,:] = i\n",
        "                globalCount += 1\n",
        "                classCount += 1\n",
        "\n",
        "    #Remove the unused entries of X and Y\n",
        "    print(\"Total number of samples\",globalCount)\n",
        "    X = X[:globalCount,:]\n",
        "    Y = Y[:globalCount,:]\n",
        "\n",
        "    return X,Y,labelNames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A23aTrqm85i_"
      },
      "outputs": [],
      "source": [
        "K=2\n",
        "imHeight=100\n",
        "imWidth=100\n",
        "\n",
        "#Call the buildDataset function\n",
        "\n",
        "#Check the built dataset classes\n",
        "print(\"Used labels\",labelNames)\n",
        "print(\"Size of data matrix\", X.shape)\n",
        "print(\"Class labels\", Y.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnsGttTt85jC"
      },
      "source": [
        "**c)** Split the dataset into a train (80% of samples) and a test set (20% samples) subsets. Make sure the data are shuffled before the split, such that the proportion of the two classes is similar in the train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P3ROrPE85jC"
      },
      "outputs": [],
      "source": [
        "#PUT your code here, and check the obtained matrices\n",
        "\n",
        "print(\"size of train dataset\",X_train.shape)\n",
        "print(\"size of test dataset\",X_test.shape)\n",
        "print(\"train target vector\",Y_train.T)\n",
        "print(\"test target vector\",Y_test.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6ABmSDq85jE"
      },
      "source": [
        "**a) Linear SVM** Create an SVC model with a linear kernel and default values ``svmLin=SVC(kernel='linear')``.\n",
        "\n",
        "* Fit the SVC on the training dataset and make predictions on the test set.\n",
        "\n",
        "* Print the vector of ground truth values and the vector of predictions.\n",
        "* Compute  the number of errors made.\n",
        "* Run the SVC.score() function.\n",
        "* Activate probabilities ``svmLin = SVC(kernel='linear',probability=True)``.\n",
        "* Make probabilistic predictions ``svmLin.predict_proba``\n",
        "\n",
        "* **QUESTIONS**\n",
        "  * Is it necessary to normalize the features before training?\n",
        "  * Which metric is being computed by SVC.score()\n",
        "  * How are the probabilistic predictions computed? (check the documentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYSk578A85jE"
      },
      "outputs": [],
      "source": [
        "# Create, train and test an svm model\n",
        "\n",
        "\n",
        "# Create, train and test a \"probabilistic\" SVM model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EOYy0VMZGlw"
      },
      "source": [
        "**b) Support vectors**\n",
        "* By looking at the dimensions of the data matrix, how many parameters does the **model** have? (Hint: the answer is not SVC.get_params())\n",
        "* How many hyperparameters does the model have?\n",
        "* How many support vectors?\n",
        "* Check the SVC class attributes https://scikit-learn.org/dev/modules/generated/sklearn.svm.SVC.html and identify the learnable parameters, the support vectors and the dual variables\n",
        "* Display the support vectors\n",
        "* Relying on the lecture, compute the model parameters from the dual coefficients. Verify the obtained result corresponds to the estimated parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpR5mAX4-iLh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB7bLuY8-jV7"
      },
      "source": [
        "**c) Kernel SVMs.**\n",
        "* Train three additional SVC models each using one among the kernel functions:\n",
        "```\n",
        "'kernel': ['rbf','poly', 'sigmoid'],\n",
        "```\n",
        "keep all other parameters to their default value.\n",
        "\n",
        "* Report the number of support vectors found after fitting for each Kernel\n",
        "* What are the hyperparameters available in each case?\n",
        "* Report the number of errors and the accuracy for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rit1LUS7HIg"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1MItOP4cjP-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q6m2JkWkdT5"
      },
      "source": [
        "**d)Hyperparameter tuning**\n",
        "Tune the hyperparameters of both the linear and the non-linear SVMs using a crossvalidation strategy. Resplit the training set into training and validation or use the ``GridSearchCV`` functionality from sklearn. In the later case  EXPLAIN how the dataset was and the criteria used to retain a given set of hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vip_7pbnkgiG"
      },
      "outputs": [],
      "source": [
        "# Some values for reference, you might change this for improved results\n",
        "param_grid = {'C': [0.1,1, 10, 100],\n",
        "              'gamma': [1,0.1,0.01,0.001],\n",
        "              'degree': [2, 3, 5]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2pD7gcW85jF"
      },
      "source": [
        "## 3. PERFORMANCE MEASURES\n",
        "**a) Fill in the function bellow to computing different evaluation measures and give a performance report**\n",
        "Look at the formulas and definitions in https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)\n",
        "\n",
        "Start by computing the confusion matrix values TP, TN, FP, FN\n",
        "\n",
        "You can use the code bellow as guide or define your own functions\n",
        "\n",
        "**Hint:** Add a numerical zero eps to the denominators to prevent dividing by zero\n",
        "\n",
        "Compare your results vs the in-built sklearn measures:\n",
        "```from sklearn.metrics import classification_report```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss0btkVw85jG"
      },
      "outputs": [],
      "source": [
        "# Functions to compute the errors between prediction and ground truth\n",
        "\n",
        "def compute_measures(Y_gt,Y_pred, positiveClass=1): #Y_gt = ground truth\n",
        "    measures = dict()\n",
        "    Y_len = len(Y_gt)\n",
        "\n",
        "    eps = 1e-12\n",
        "\n",
        "    # True positives TP\n",
        "    TP =\n",
        "\n",
        "    # True negatives TN\n",
        "    TN =\n",
        "\n",
        "    # False positives FP\n",
        "    FP =\n",
        "\n",
        "    # False negatives FN\n",
        "    FN =\n",
        "\n",
        "    print('TP ', TP, 'TN ', TN, 'FP', FP, 'FN', FN, 'Total', TP+TN+FP+FN)\n",
        "    measures['TP'] = TP\n",
        "    measures['TN'] = TN\n",
        "    measures['FP'] = FP\n",
        "    measures['FN'] = FN\n",
        "\n",
        "\n",
        "    # Accuracy\n",
        "    measures['accuracy'] =\n",
        "\n",
        "    # Precision\n",
        "    measures['precision'] =\n",
        "\n",
        "    # Specificity\n",
        "    measures['specificity']=\n",
        "\n",
        "    # Recall\n",
        "    measures['recall'] =\n",
        "\n",
        "    # F-measure\n",
        "    measures['f1'] =\n",
        "\n",
        "    # Negative Predictive Value\n",
        "    measures['npv'] =\n",
        "\n",
        "    # False Positive Rate\n",
        "    measures['fpr'] =\n",
        "\n",
        "    print('Accuracy ', measures['accuracy'], '\\n',\n",
        "          'Precision', measures['precision'], '\\n',\n",
        "          'Recall', measures['recall'], '\\n',\n",
        "          'Specificity ', measures['specificity'], '\\n',\n",
        "          'F-measure', measures['f1'], '\\n',\n",
        "          'NPV', measures['npv'],'\\n',\n",
        "          'FPV', measures['fpr'],'\\n')\n",
        "\n",
        "    return measures\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXMqcNVOG1yn"
      },
      "source": [
        "**b) ROC curves**\n",
        "- Plot the ROC curves of all the trained svm models (with different kernels including linear) before and after the hyperparameter tuning. Comment the results\n",
        "- Compare the roc curves of the best obtained models for each kernel between.\n",
        "- Add a curve for a  logistic regression model.\n",
        "\n",
        "You might use your own thresholding function or use the ``roc_curve`` functionality from scikit learn\n",
        "\n",
        "Hint: To threshold we need to make probabilistic predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK7mXCQJopRs"
      },
      "outputs": [],
      "source": [
        "# Fit a logistic regression model here and make probabilistic predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7SkVO85oyh_"
      },
      "outputs": [],
      "source": [
        "# plot no skill roc curve\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n",
        "\n",
        "# calculate roc curve for logistic regression\n",
        "fpr, tpr, _ = roc_curve(Y_test, Y_pred_logreg_probas[:,1])\n",
        "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# show the legend\n",
        "plt.legend()\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50WjtVRQ85jK"
      },
      "source": [
        "**c) Qualitative Results** Using your best model, show some of the test images and write on the title the predictions vs the ground truth labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_xba2ji85jL",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Show some results\n",
        "width=20\n",
        "height=15\n",
        "plt.rcParams['figure.figsize'] = [width, height]\n",
        "\n",
        "#Change your predictions vector here\n",
        "Y_best=Y_rbfBest\n",
        "\n",
        "fig=plt.figure()\n",
        "imCounter = 1\n",
        "for i in range(len(Y_test)):\n",
        "    image=np.reshape(X_test[i,:], (imHeight,imWidth))\n",
        "\n",
        "    plt.subplot(5,7,imCounter)\n",
        "    plt.imshow(image,cmap='gray')\n",
        "    plt.axis('off')\n",
        "    gtLabel = labelNames[Y_test.ravel()[i].astype(int)]\n",
        "    predLabel = labelNames[Y_best.ravel()[i].astype(int)]\n",
        "    plt.title('GT: {}. \\n Pred: {}'.format(gtLabel, predLabel))\n",
        "\n",
        "    imCounter += 1\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkOEYriCqPA3"
      },
      "source": [
        "**d) REPORT:** Starting from the best model, analyse and discuss the behaviour for different SVC hyperparameters, choice of classes, and numbers of images in each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGeHBtGiqb1s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
